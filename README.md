# ONNX Runtime Inference Demo

Use ORT to inference model at Android device by Java. Inference time is 17ms.
